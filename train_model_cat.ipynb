{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_cat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EBuMAlMWyHJsPQaM8ERJkEa2trcTI7u5",
      "authorship_tag": "ABX9TyNfqEFcIpt6aajc+HE2tNuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maybachar/getpet-recognition/blob/master/train_model_cat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMlTMMVT4dL8",
        "outputId": "c7b6bba9-fb30-46e0-ed81-937236d9783d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "\n",
        "#append to lables list the suitale lable for each image using info from csv file\n",
        "#and add the number of breed instead the name breed(using dictionary).   \n",
        "def create_lables_list(image_id, lables):\n",
        "    image_id = image_id.split(\"/\")[-1].split(\".\")[0]\n",
        "    # get breed name by image id from labels.csv\n",
        "    breed_name = list(labels_file[labels_file.id == image_id][\"breed\"])[0]\n",
        "    # get the number of this breed and append it to list.\n",
        "    breed_idx = breed_num_dic[breed_name]\n",
        "    lables.append(breed_idx)\n",
        "\n",
        "\n",
        "def build(size, num_classes):\n",
        "    # the input size the model will get. default size for mobile and 3 is for colors.\n",
        "    inputs = Input((size, size, 3))\n",
        "    # create the base pre-trained model.\n",
        "    base_model = MobileNetV2(input_tensor=inputs, include_top=False,\n",
        "                           weights=\"imagenet\")\n",
        "    # set all parameters to be trainable\n",
        "    base_model.trainable = True\n",
        "    # get the model so we can add layers to it.\n",
        "    x = base_model.output\n",
        "    # add a global spatial average pooling layer\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # include a dropout layer to minimize the overfitting.\n",
        "    x = Dropout(0.2)(x)\n",
        "    # using activation function RELU- widely used in CNN.\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    # add softmax layer for getting probabilities on the breeds.\n",
        "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    # create the model with it's layers.\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fix_data_element(path, y):\n",
        "    num_class = 12\n",
        "    size = 224\n",
        "    path = path.decode()\n",
        "    # loads a color image from the specified file.\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # change the width, height of an image.\n",
        "    image = cv2.resize(image, (size, size))\n",
        "    # normaliztion.\n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    # one hot encoding to lable (all zero except for the place y).\n",
        "    label = [0] * num_class\n",
        "    label[y] = 1\n",
        "    label = np.array(label)\n",
        "    label = label.astype(np.int32)\n",
        "    return image, label\n",
        "\n",
        "def parse(x, y):\n",
        "    num_class = 12\n",
        "    size = 224\n",
        "    # wrap numpy function as an operation in TensorFlow function.\n",
        "    x, y = tf.numpy_function(fix_data_element, [x, y], [tf.float32, tf.int32])\n",
        "    # resize image to the image size mobilenet expect to get.\n",
        "    x.set_shape((size, size, 3))\n",
        "    y.set_shape((num_class))\n",
        "    return x, y\n",
        "\n",
        "def fix_dataset(x, y, batch=8):\n",
        "    # get the slices of x and y into one dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    # execute fix_data function on every element of the Dataset separately.\n",
        "    dataset = dataset.map(parse)\n",
        "    # combines consecutive elements of a dataset object into batches.\n",
        "    dataset = dataset.batch(batch)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # image size\n",
        "    size = 224\n",
        "    num_breeds = 12\n",
        "    # learning rate 0.0001.\n",
        "    lr = 0.0001\n",
        "    batch = 16\n",
        "    epochs = 5\n",
        "\n",
        "    # paths of train data folder and csv file with labels of each pic.\n",
        "    path = \"/content/drive/MyDrive/cat-breed-identification/\"\n",
        "    train_path = os.path.join(path, \"images/images/*\")\n",
        "    labels_path = os.path.join(path, \"cat_labels.csv\")\n",
        "    # import the CSV file.\n",
        "    labels_file = pd.read_csv(labels_path)\n",
        "    # get all unique breeds in file.\n",
        "    breed = labels_file[\"breed\"].unique()\n",
        "    # create dictionary of breed and number.\n",
        "    breed_num_dic = {name: i for i, name in enumerate(breed)}\n",
        "    # ids of photos\n",
        "    ids = glob(train_path)\n",
        "    # list of breed index by order of image id\n",
        "    lables = []\n",
        "    # adding the num of breed-the lable of each image to lables list.\n",
        "    for image_id in ids:\n",
        "        create_lables_list(image_id, lables)\n",
        "\n",
        "    # work only with N image id and N lables of the breed id which suitable to the images.\n",
        "    ids = ids[:2350]\n",
        "    lables = lables[:2350]\n",
        "\n",
        "    # spliting data to train and validation.\n",
        "    train_x, validation_x = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "    train_y, validation_y = train_test_split(lables, test_size=0.2, random_state=42)\n",
        "    #create a CNN model with it's layers.\n",
        "    model = build(size, num_breeds)\n",
        "    #Configures the model for training. optimizer- adam.\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr), metrics=[\"acc\"])\n",
        "    # dataset\n",
        "    trainSet = fix_dataset(train_x, train_y, batch=batch)\n",
        "    validationSet = fix_dataset(validation_x, validation_y, batch=batch)\n",
        "\n",
        "    # train\n",
        "    #set of functions to be applied at training procedure:\n",
        "    # modelCheckPoint saves the model after every epoch.\n",
        "    # Reduce learning rate when a metric has stopped improving.\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=2, min_lr=0.000001)\n",
        "    ]\n",
        "    # Trains the model for number of epochs. evaluate the loss at the end of each epoch.\n",
        "    model.fit(trainSet, validation_data=validationSet, epochs=epochs, callbacks=callbacks)\n",
        "    # save the model and it's weights in H5 format to jeson file.\n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/drive/MyDrive/cat-breed-identification/model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "        model.save_weights(\"/content/drive/MyDrive/cat-breed-identification/model.h5\")\n",
        "        print(\"Saved model to disk\")\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 1560s 13s/step - loss: 1.1061 - acc: 0.6457 - val_loss: 0.9818 - val_acc: 0.6596\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.98184, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "118/118 [==============================] - 357s 3s/step - loss: 0.2070 - acc: 0.9436 - val_loss: 0.7029 - val_acc: 0.7362\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.98184 to 0.70285, saving model to model.h5\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 356s 3s/step - loss: 0.0456 - acc: 0.9957 - val_loss: 0.5695 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.70285 to 0.56948, saving model to model.h5\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 354s 3s/step - loss: 0.0133 - acc: 0.9995 - val_loss: 0.6049 - val_acc: 0.7957\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.56948\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 362s 3s/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.56948 to 0.52538, saving model to model.h5\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}