{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_dog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IPIoAQ9bpg-VYGKpcmG4xYiL3NZ6jfZj",
      "authorship_tag": "ABX9TyPJ4Zx9V4K/XSfJAKvgESp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maybachar/getpet-recognition/blob/master/train_model_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppa7154GeoJ_",
        "outputId": "f2d051a7-0c6a-4bc6-c240-f2bf382ffbdc"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# num of breeds and image size.\n",
        "num_breeds = 120\n",
        "size = 224\n",
        "\n",
        "# Append to lables list the suitale lable for each image using info from csv file\n",
        "# and add the number of breed instead the name breed(using dictionary).   \n",
        "def create_lables_list(img_id, img_lables,labels_file, breed_num_dic):\n",
        "    img_id = img_id.split(\"/\")[-1]\n",
        "    img_id = img_id.split(\".\")[0]\n",
        "    # get breed name by image id from labels.csv\n",
        "    breed_name = list(labels_file[labels_file.id == img_id][\"breed\"])[0]\n",
        "    # get the number of this breed and append it to list.\n",
        "    breed_idx = breed_num_dic[breed_name]\n",
        "    img_lables.append(breed_idx)\n",
        "\n",
        "\n",
        "def build():\n",
        "    # The input size the model will get. default size for mobile and 3 is for colors.\n",
        "    inputs_model = Input((size, size, 3))\n",
        "    # Create the base pre-trained model.\n",
        "    base_model = MobileNetV2(input_tensor=inputs_model, include_top=False,weights=\"imagenet\", input_shape=(size, size, 3))\n",
        "    # Set all parameters to be trainable\n",
        "    base_model.trainable = True\n",
        "    # Get the model so we can add layers to it.\n",
        "    model_out = base_model.output\n",
        "    # Add a global spatial average pooling layer\n",
        "    model_out = GlobalAveragePooling2D()(model_out)\n",
        "    # Include a dropout layer to minimize the overfitting.\n",
        "    model_out = Dropout(0.2)(model_out)\n",
        "    # Using activation function RELU- widely used in CNN.\n",
        "    model_out = Dense(1024, activation=\"relu\")(model_out)\n",
        "    # Add softmax layer for getting probabilities on the breeds.\n",
        "    model_out = Dense(num_breeds, activation=\"softmax\")(model_out)\n",
        "    # Create the model with it's layers.\n",
        "    model = tf.keras.Model(inputs_model, model_out)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fix_data_element(path, y):\n",
        "    # one hot encoding to lable (all zero except for the place y).\n",
        "    one_hot_y = [0] * num_breeds\n",
        "    one_hot_y[y] = 1\n",
        "    one_hot_y = np.array(one_hot_y)\n",
        "    # Cast to type as defined.\n",
        "    one_hot_y = one_hot_y.astype(np.int32)\n",
        "    path = path.decode()\n",
        "    # loads a color image from the specified file.\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # change the width, height of an image.\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    # normaliztion.\n",
        "    img = img / 255.0\n",
        "    img = img.astype(np.float32)\n",
        "    return img, one_hot_y\n",
        "\n",
        "def wrap_elements(x, y):\n",
        "    # wrap numpy function as an operation in TensorFlow function.\n",
        "    x, y = tf.numpy_function(fix_data_element, [x, y], [tf.float32, tf.int32])\n",
        "    # resize image to the image size mobilenet expect to get.\n",
        "    x.set_shape((size, size, 3))\n",
        "    y.set_shape((num_breeds))\n",
        "    return x, y\n",
        "\n",
        "def fix_dataset(x, y, batch):\n",
        "    # get the slices of x and y into one dataset.\n",
        "    data_slices = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    # wrap with fix_data_element function every element of the Dataset separately and resize.\n",
        "    data_slices = data_slices.map(wrap_elements)\n",
        "    # combines consecutive elements of a dataset object into batches.\n",
        "    data_slices = data_slices.batch(batch)\n",
        "    return data_slices\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # learning rate 0.0001.\n",
        "    lr = 0.0001\n",
        "    batch = 16\n",
        "    epochs = 5\n",
        "    # paths of train data folder and csv file with labels of each pic.\n",
        "    path = \"/content/drive/MyDrive/dog_breed_identification/\"\n",
        "    train_path = os.path.join(path, \"train/*\")\n",
        "    labels_path = os.path.join(path, \"labels.csv\")\n",
        "    # import the CSV file.\n",
        "    labels_file = pd.read_csv(labels_path)\n",
        "    # get all unique breeds in file.\n",
        "    breed = labels_file[\"breed\"].unique()\n",
        "    length_breed=len(breed)\n",
        "    breed_num_dic = {}\n",
        "    # create dictionary of breed and number.\n",
        "    for i in range(length_breed):\n",
        "      breed_num_dic[breed[i]] = i\n",
        "    # ids of photos\n",
        "    all_img_ids = glob(train_path)\n",
        "    # list of breed index by order of image id\n",
        "    img_lables = []\n",
        "    # adding the num of breed-the lable of each image to lables list.\n",
        "    for image_id in all_img_ids:\n",
        "        create_lables_list(image_id, img_lables,labels_file, breed_num_dic)\n",
        "    # work only with N image id and N lables of the breed id which suitable to the images.\n",
        "    all_img_ids = all_img_ids[:]\n",
        "    img_lables = img_lables[:]\n",
        "    # spliting data to train and validation.\n",
        "    train_x, validation_x = train_test_split(all_img_ids, test_size=0.2, random_state=42)\n",
        "    train_y, validation_y = train_test_split(img_lables, test_size=0.2, random_state=42)\n",
        "    # dataset\n",
        "    trainSet = fix_dataset(train_x, train_y, batch=batch)\n",
        "    validationSet = fix_dataset(validation_x, validation_y, batch=batch)\n",
        "    #create a CNN model with it's layers.\n",
        "    model = build()\n",
        "    #Configures the model for training. optimizer- adam.\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr), metrics=[\"acc\"])\n",
        "    # Train\n",
        "    # set of functions to be applied at training procedure:\n",
        "    # modelCheckPoint saves the model after every epoch.\n",
        "    # Reduce learning rate when a metric has stopped improving.\n",
        "    callbacks = [ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=2, min_lr=0.000001)]\n",
        "    # Trains the model for number of epochs. evaluate the loss at the end of each epoch.\n",
        "    model.fit(trainSet, validation_data=validationSet, epochs=epochs, callbacks=callbacks)\n",
        "    # save the model and it's weights in H5 format to jeson file.\n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/drive/MyDrive/dog_breed_identification/model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "        model.save_weights(\"/content/drive/MyDrive/dog_breed_identification/model.h5\")\n",
        "        print(\"Saved model to disk\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 2243s 4s/step - loss: 2.7838 - acc: 0.3358 - val_loss: 1.6946 - val_acc: 0.5237\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.69456, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "512/512 [==============================] - 1654s 3s/step - loss: 0.9585 - acc: 0.7316 - val_loss: 1.3319 - val_acc: 0.6039\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.69456 to 1.33192, saving model to model.h5\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 1624s 3s/step - loss: 0.3390 - acc: 0.9188 - val_loss: 1.2531 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.33192 to 1.25305, saving model to model.h5\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 1625s 3s/step - loss: 0.1078 - acc: 0.9865 - val_loss: 1.1641 - val_acc: 0.6670\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.25305 to 1.16410, saving model to model.h5\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 1640s 3s/step - loss: 0.0411 - acc: 0.9967 - val_loss: 1.0942 - val_acc: 0.6841\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.16410 to 1.09423, saving model to model.h5\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}